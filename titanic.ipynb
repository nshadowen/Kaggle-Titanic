{"nbformat_minor": 1, "cells": [{"source": ["# Introduction\n", "This is my first Kaggle competition, in which we analyze data provided by Kaggle to determine which individuals on the Titanic were more likely to have survived based on a set of the most significant features.\n", "\n", "My process for analyzing the data is as follows: \n", "1. Data Preprocessing\n", "    1. Importing the libraries\n", "    2. Importing the dataset\n", "    3. Taking care of missing data\n", "        1. Age\n", "        2. Cabin Number\n", "        3. Location from which Individual Embarked\n", "    4. Encoding Categorical Data\n", "    5. Splitting the training set into 80% training data, 20% testing\n", "    6. Feature Scaling\n", "2. Individual Data Relationship Analysis\n", "3. Logistic Regression\n", "4. Random Forest\n", "5. Model Assessment \n", "6. Conclusion\n", "\n", "Many thanks to Kirill Eremenko and Hadelin de Ponteves for their amazing course Machine Learning A-Z\u2122: Hands-On Python & R In Data Science available on udemy.com. I used mostly what I learned there to complete my first kaggle kernel!\n", "Also thanks to SaraG on Kaggle for her awesome kernel, really helped me figure out how to do this for the first time. :) Check it out here: https://www.kaggle.com/sgus1318/titanic-analysis-learning-to-swim-with-python."], "cell_type": "markdown", "metadata": {"_cell_guid": "04e069f9-498a-4b7e-bfda-cce00e1b8b40", "_uuid": "734926cb690f6d3e149704120cde6e3613f278b7"}}, {"source": ["# 1. Data Pre-Processing"], "cell_type": "markdown", "metadata": {"_cell_guid": "ee0a6f44-e8c6-475b-a6b0-b72b8ffc71d9", "_uuid": "0ecd1b2258f5ff011d0392ac262d514d8d879a47"}}, {"source": ["## 1.A. Importing the libraries"], "cell_type": "markdown", "metadata": {"_cell_guid": "d5493fad-1622-4684-b001-68cd496a67ee", "_uuid": "89b4d7e66656886bf4531476746e4bb00ed2fe19"}}, {"source": ["# importing the libraries\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import re\n", "\n", "import seaborn as sns\n", "sns.set_style('whitegrid')\n", "%matplotlib inline\n"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "7c674fe6-325e-4e8e-a1ae-d69f64a8b3ce", "collapsed": true, "_uuid": "3c8af3911d3cff8d0964f0380092c1488eb29471"}}, {"source": ["## 1.B. Importing the data"], "cell_type": "markdown", "metadata": {"_cell_guid": "9f6f2cde-9d52-442c-bf18-4056f75ecd44", "_uuid": "9efdc1ea7d6b1da51d7d024747c19f0352abad17"}}, {"source": ["# importing the training dataset\n", "titanic_train_df = pd.read_csv('../input/train.csv')\n", "\n", "#X = titanic_train_df.iloc[:, 2:12].values\n", "#y = titanic_train_df.iloc[:, 1].values\n", "\n", "# importing the test dataset (test-data for the challenge)\n", "titanic_test_df = pd.read_csv('../input/test.csv')\n"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "e8987262-bba3-41bb-bb35-fd0687ea398f", "collapsed": true, "_uuid": "89ad2c16d685d8a3d4d8b70c992d5968d8632339"}}, {"source": ["# snapshot of top 5 rows of training dataframe\n", "titanic_train_df.head()"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "be853aaf-d1e5-4e6d-8e06-d7aca14e75f9", "_uuid": "d0cb1d871c093c08398afdca4a44f1b48e1f771b"}}, {"source": ["# snapshot of top 5 rows of testing dataframe\n", "titanic_test_df.head()\n", "\n", "# Note: no survival data because this is what we are predicting for the challenge."], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "7db441fb-6176-4e1c-b7ad-1cf0f9254f54", "_uuid": "41f84dbc0f939295e84f04db1d4fcb95020f1012"}}, {"source": ["## 1.C. Taking care of missing data"], "cell_type": "markdown", "metadata": {"_cell_guid": "7544863d-c9c6-4386-bc3b-b63301a02cae", "_uuid": "530ff34667bd9361a06cae57a040ec0f37261534"}}, {"source": ["#### Age, cabin, and embarked from location are all variables with missing values which we need to correct for before moving forward with our variable analysis.  For each of these variables, we first found how many values were missing out of the total passengers in the training set, to determine our approach to filling in the missing values. Typically, the decision for filling in values is to ignore, remove, fill in a value (using mean, median, mode, back fill, or forward fill), or replace the value with a static value. "], "cell_type": "markdown", "metadata": {"_cell_guid": "c13c9122-4547-4109-a84d-0be05555d792", "_uuid": "e4239415894e167952608d59fc7cfc3c0a39ffd1"}}, {"source": ["# see how many values are in each column of training dataset\n", "len(titanic_train_df['PassengerId'])"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "e53a485c-fe52-448a-a092-8c24254e4381", "_uuid": "95d993ece6dd4751a15d130747deaeb42c9ac79d"}}, {"source": ["# see how many values are missing in training dataset\n", "titanic_train_df.isnull().sum()"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "84f6c58f-757e-4444-adc9-7215d44b4228", "_uuid": "e9cecba6d56eea024cd880807c280c149db332ce"}}, {"source": ["### 1.C.a Age"], "cell_type": "markdown", "metadata": {"_cell_guid": "8c494649-998c-4397-9c21-1907e659d277", "_uuid": "97cc98e4f5fbdcd2593e07bc8a63593ac20ad709"}}, {"source": ["# Number of null values in Age column\n", "sum(pd.isnull(titanic_train_df['Age']))"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "ba6089fb-acb1-4c77-a0cc-6e8b4f4314d3", "_uuid": "a17c8be9f2bcb0ce19b05a3a4c9c3c2833456d29"}}, {"source": ["# Percentage of Age column having values\n", "sum(pd.isnull(titanic_train_df['Age']))/891 # 891 is the total number of individuals in the dataset found above"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "83a6a966-4f13-4ac5-8ce2-96f62c422d02", "_uuid": "aaf12a19ec7e351335d69d397a8c93c69f752267"}}, {"source": ["#### Only 20% of age is null. This is a signifitherefore, we keep age"], "cell_type": "markdown", "metadata": {"_cell_guid": "26839814-3d6d-4e31-ac88-0c65ce9e21e5", "_uuid": "d847765045638c3268a74a966038b027f8bddfe5"}}, {"source": ["# Attempt to use Imputer from sklearn, but couldn't get it to work this time..\n", "#from sklearn.preprocessing import Imputer\n", "#imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 1)\n", "#q = imputer.fit_transform(titanic_train_df([\"Age\"]).T\n", "#titanic_train_df[\"Age\"] = q"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "a50be339-493a-49f4-bee5-587ea4d293ec", "collapsed": true, "_uuid": "331afb5ba7e6465e8f24dbd3c72b45fcf0773ff8"}}, {"source": ["# Fill in missing values with mean for missing Age values\n", "titanic_train_df[\"Age\"].fillna(titanic_train_df[\"Age\"].mean(), inplace=True)\n", "\n", "# check out the first 100 data points\n", "titanic_train_df.head(100)"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "bd4ac3d4-ed2b-40a3-990d-91eb8f5bf4b9", "_uuid": "272e3849d48639aea104a62246b71f2103b26e43"}}, {"source": ["# Do the same with Age column in test set\n", "titanic_test_df[\"Age\"].fillna(titanic_train_df[\"Age\"].mean(), inplace=True)"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "5fa40563-e312-4726-8469-2ac512562a9d", "collapsed": true, "_uuid": "938e8624d1e244282389207c6b663fac116afacb"}}, {"source": ["#def findWholeWord(w):\n", "#   return re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search\n", "\n", "#name_string = str(titanic_train_df['Name'])\n", "#while findWholeWord('Miss')(name_string) == True:\n", "#    titanic_train_df['Title'] = 'Miss'\n", "#titanic_train_df.head()"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "fa305a6c-7e11-4175-820e-7444acc43cbf", "collapsed": true, "_uuid": "ad0e6419e18966e4c297204f950c2b0f7439c983"}}, {"source": ["#What is each person's title? \n", "#titanic_train_df['Title'] = titanic_train_df['Name'].map(lambda x: re.compile(\", (.*?).\").findall(x)[0])\n", " \n", "# Group low-occuring, related titles together\n", "#titanic_train_df['Title'][titanic_train_df.Title == 'Jonkheer'] = 'Master'\n", "#titanic_train_df['Title'][titanic_train_df.Title.isin(['Ms','Mlle'])] = 'Miss'\n", "#titanic_train_df['Title'][titanic_train_df.Title == 'Mme'] = 'Mrs'\n", "#titanic_train_df['Title'][titanic_train_df.Title.isin(['Capt', 'Don', 'Major', 'Col', 'Sir'])] = 'Sir'\n", "#titanic_train_df['Title'][titanic_train_df.Title.isin(['Dona', 'Lady', 'the Countess'])] = 'Lady'\n", "\n", "#titanic_train_df['Title'] = 'Master'\n", "\n", "# Build binary features\n", "#titanic_train_df = pd.concat([titanic_train_df, pd.get_dummies(titanic_train_df['Title']).rename(columns=lambda x: 'Title_' + str(x))], axis=1)\n", "#master_number = 0\n", "#if titanic_train_df['Title'] == 'Master':\n", "        #master_number += 1\n", "        #titanic_train_df['Age'] \n", "#titanic_train_df.head(10)\n", "#print(master_number)"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "15fec85e-9c5a-4fda-9f04-db82f0ce213e", "collapsed": true, "_uuid": "882ee7e40ff1ee77aa1b40c4fcbbb81f92fa17b3"}}, {"source": ["### 1.C.b Cabin\n", "For the variable Cabin, we start by analyzing the amount of missing values."], "cell_type": "markdown", "metadata": {"_cell_guid": "d4144995-a4c0-424f-9d7b-ea8e226863d1", "_uuid": "e1c2a51587026ca4be6d83cad71fefc7235dcea9"}}, {"source": ["sum(pd.isnull(titanic_train_df['Cabin']))"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "15862f9b-2e2c-4133-9569-1a787a3c2527", "_uuid": "3bfebd1325d19ed75a9fc49bfbbfa0ace8b27ed8"}}, {"source": ["sum(pd.isnull(titanic_train_df['Cabin']))/891"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "abf15729-92cb-4c9b-bc3a-ed91b742922b", "_uuid": "1b80ac1e3d67ea0e898159c965c8943857633c45"}}, {"source": ["77% of the values for Cabin are missing. Therefore, we will not consider this variable."], "cell_type": "markdown", "metadata": {"_cell_guid": "7e2a1bf1-f96d-4a55-be94-6dffe77bc290", "_uuid": "aa5c16b17caf7a738ee48faa731c5406420c0cb2"}}, {"source": ["# Drop Cabin column from the data as over 75% of data is missing from training set\n", "titanic_train_df.drop(\"Cabin\",axis=1,inplace=True)\n", "\n", "#Do the same with test set\n", "titanic_test_df.drop(\"Cabin\",axis=1,inplace=True)\n", "\n", "# Verify both have been removed\n", "titanic_train_df.head()\n", "titanic_test_df.head()"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "11bb360c-3ccb-4fb8-9f2f-f5ad2fead0f2", "_uuid": "52464fe572088128a41e0d3bbbcd4c5ba7afc6ed"}}, {"source": ["### 1.C.c. Embarkment Location"], "cell_type": "markdown", "metadata": {"_cell_guid": "1c63bc9e-391b-43a5-b903-174661a3ed63", "_uuid": "4c1b9c1108ea026ac900fd7380a3a31f6734506c"}}, {"source": ["Like the other variables, we first find the number of missing embarkment location values."], "cell_type": "markdown", "metadata": {"_cell_guid": "83228319-1e52-4cdc-8ae6-1f7ca242e4b2", "_uuid": "dda230d325e29ee89a271a06320596d6dc635995"}}, {"source": ["sum(pd.isnull(titanic_train_df['Embarked']))"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "fd5ed1ff-e817-44c1-b54d-76b06d6b8ee0", "_uuid": "79d5068a2e809917db2484cad5a080b05f89e383"}}, {"source": ["# Find proportion of missing Embarked values\n", "sum(pd.isnull(titanic_train_df['Embarked']))/891"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "1b572cb1-1b70-4c99-b5a7-2210608dfc22", "_uuid": "ff6eb6f7349d0c3f88ebc058fe1e54364acda4fe"}}, {"source": ["The proportion of missing embarked values is less than 1%, so this variable is worth keeping. Let's look further at the feature itself."], "cell_type": "markdown", "metadata": {"_cell_guid": "ed43c102-9502-46d7-a64c-7994cf2e3d56", "_uuid": "d37b1daeb078aee18860b48c0fa3b89b2a5cc9a5"}}, {"source": ["sns.countplot(x='Embarked', data=titanic_train_df,palette='GnBu_d')\n", "plt.xlabel('Embarkment Location')\n", "plt.ylabel('Number of People')\n", "plt.xticks( np.arange(3), \n", "           ('Southampton (S)', 'Cherbourg (C)', 'Queenstown (Q)') )\n", "plt.show()\n", "titanic_train_df['Embarked'].value_counts()\n", "#titanic_train_df.Embarked.hist(alpha=.75,bins=5, color='mediumturquoise')"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "a0d26823-a05d-4d12-bfbf-a89606835be4", "_uuid": "6a355e0ee5b332c791d17259b02c017e2a417ecc"}}, {"source": ["From our analysis, the people onboard the Titanic were overwhelmingly from Southampton. Becuase we only have two missing Embarkment location values, we will replace them with the majority location for both the training and test set."], "cell_type": "markdown", "metadata": {"_cell_guid": "afb3fa7c-3e3f-4164-8786-6ca4289e9f1c", "_uuid": "c06aaf31f2dfb006698b0dcd4ca800788b985f44"}}, {"source": ["# Replace 'NaN' values with S \n", "titanic_train_df['Embarked'].fillna('S',inplace=True)\n", "titanic_test_df['Embarked'].fillna('S',inplace=True)"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "38843d87-8985-4094-9c34-7b954829b6e4", "_uuid": "534c3ea5e86783d024774649656f9fe3d559c611"}}, {"source": ["Last thing we do in our Missing Data section is check both the training and test set to make sure we no longer have any null values."], "cell_type": "markdown", "metadata": {"_cell_guid": "03a9f1e5-2faa-4d86-9521-33cf920350a8", "_uuid": "5eaa99b57f874451d3419ed3e4652a58cb69badd"}}, {"source": ["titanic_train_df.isnull().sum()\n", "print(\"-------------------------\")\n", "titanic_test_df.isnull().sum()"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "8065eee2-d9e9-48af-8c78-0a4dda3ebe43", "_uuid": "892095008dd8111776a92ad258dc3e2bbbf4515e"}}, {"source": ["There is one missing Fare value in our test data. Since it is only one, we will replace this with the median value of the other fare values."], "cell_type": "markdown", "metadata": {"_cell_guid": "4700c626-eb48-43ad-84d6-aa682be4dd54", "_uuid": "9450380f48243375e5af517d48f66fb6e6cda6a5"}}, {"source": ["titanic_test_df[\"Fare\"].fillna(titanic_test_df['Fare'].median(),inplace=True)"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "0498d29f-9fdd-4de8-996b-24057473e88d", "_uuid": "18406ea0f5086403c4dbae66ce1c02a7a3bba428"}}, {"source": ["titanic_train_df.isnull().sum()\n", "print(\"------------------------\")\n", "titanic_test_df.isnull().sum()"], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "952b0e63-b871-4b4a-9c76-ce5b60e8cf6a", "_uuid": "1e11815f52a4fed74297d6b0f430cf6db70b297a"}}, {"source": ["Now we are ready to encode the categorical data, and get analyzing!"], "cell_type": "markdown", "metadata": {"_cell_guid": "ee4d9410-fef6-487f-bd38-0306b8434675", "_uuid": "943c5e6645b43d0aaf1370454068402d1b666efc"}}, {"source": ["## 1.D. Encoding Categorical Data\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "b0c27a73-797f-49d8-9a98-82999c458c18", "_uuid": "47fa799c5cc374658045a34aedade7ae995dea62"}}, {"source": [], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "b4aab918-b215-4265-8281-8c9692985bff", "_uuid": "e0dbfea7008057fbca59f85a5404ec88dfc251a2"}}, {"source": [], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "00c4e75d-d3ff-4271-81fe-0ef6bc908caa", "collapsed": true, "_uuid": "44df3f7d3d2422a7c478da687becf0f939e5c189"}}, {"source": [], "outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "97cb3402-3e59-4a89-adc4-9469aaf3be39", "collapsed": true, "_uuid": "be40265caee705b917c93482bdecff309b92956e"}}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"mimetype": "text/x-python", "version": "3.6.4", "name": "python", "nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}
